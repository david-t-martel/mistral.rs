//! File operation benchmarks for winutils vs native Windows utilities
//!
//! This module provides comprehensive benchmarking of file operations
//! including I/O performance, memory usage, and CPU utilization.

use anyhow::{Context, Result};
use criterion::{black_box, Criterion, BenchmarkId, BatchSize, Throughput};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fs::{File, OpenOptions};
use std::io::{Read, Write, BufRead, BufReader, BufWriter, Seek, SeekFrom};
use std::path::{Path, PathBuf};
use std::process::Command;
use std::time::{Duration, Instant};
use tempfile::{TempDir, NamedTempFile};

/// File operation benchmark suite
#[derive(Debug)]
pub struct FileOperationBenchmarks {
    test_data_dir: TempDir,
    test_files: HashMap<String, TestFile>,
    utilities_under_test: Vec<String>,
}

/// Test file with different sizes and characteristics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct TestFile {
    pub name: String,
    pub size_bytes: u64,
    pub file_type: FileType,
    pub content_pattern: ContentPattern,
    pub path: PathBuf,
}

/// Types of test files
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum FileType {
    Text,
    Binary,
    Sparse,
    LargeText,
    SmallText,
    Unicode,
    Mixed,
}

/// Content patterns for testing
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ContentPattern {
    Random,
    Repeated,
    Sequential,
    Lines,
    Words,
    Unicode,
    Binary,
}

/// File operation benchmark results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileOperationResults {
    pub timestamp: chrono::DateTime<chrono::Utc>,
    pub system_info: crate::platforms_enhanced::SystemInformation,
    pub io_benchmarks: IOBenchmarkResults,
    pub utility_comparisons: HashMap<String, UtilityComparisonResults>,
    pub performance_summary: FileOperationSummary,
    pub memory_profiles: HashMap<String, MemoryProfile>,
    pub scalability_results: ScalabilityResults,
}

/// I/O benchmark results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct IOBenchmarkResults {
    pub read_throughput_mbps: HashMap<String, f64>,
    pub write_throughput_mbps: HashMap<String, f64>,
    pub seek_time_us: HashMap<String, f64>,
    pub small_io_latency_ns: HashMap<String, f64>,
    pub large_io_throughput: HashMap<String, f64>,
    pub concurrent_io_performance: HashMap<String, f64>,
}

/// Utility comparison results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct UtilityComparisonResults {
    pub utility_name: String,
    pub winutils_time_ms: f64,
    pub native_time_ms: f64,
    pub speedup_ratio: f64,
    pub memory_usage_mb: f64,
    pub cpu_usage_percent: f64,
    pub io_operations: u64,
    pub accuracy_score: f64,
    pub test_results: HashMap<String, SingleTestResult>,
}

/// Single test result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SingleTestResult {
    pub test_name: String,
    pub file_size_mb: f64,
    pub execution_time_ms: f64,
    pub throughput_mbps: f64,
    pub peak_memory_mb: f64,
    pub cpu_time_ms: f64,
    pub io_read_mb: f64,
    pub io_write_mb: f64,
    pub success: bool,
    pub error_message: Option<String>,
}

/// Performance summary
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FileOperationSummary {
    pub total_tests: usize,
    pub successful_tests: usize,
    pub failed_tests: usize,
    pub average_speedup: f64,
    pub best_speedup: f64,
    pub worst_speedup: f64,
    pub total_data_processed_gb: f64,
    pub average_throughput_mbps: f64,
    pub memory_efficiency_ratio: f64,
    pub cpu_efficiency_ratio: f64,
}

/// Memory profiling results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemoryProfile {
    pub utility_name: String,
    pub peak_usage_mb: f64,
    pub average_usage_mb: f64,
    pub allocation_count: u64,
    pub deallocation_count: u64,
    pub memory_leaks_mb: f64,
    pub gc_collections: u64,
    pub memory_timeline: Vec<MemorySnapshot>,
}

/// Memory snapshot at a specific time
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MemorySnapshot {
    pub timestamp_ms: u64,
    pub memory_usage_mb: f64,
    pub heap_size_mb: f64,
    pub stack_size_mb: f64,
}

/// Scalability test results
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ScalabilityResults {
    pub file_size_scaling: HashMap<u64, f64>, // file_size -> throughput
    pub concurrent_operations: HashMap<usize, f64>, // thread_count -> throughput
    pub directory_size_scaling: HashMap<usize, f64>, // file_count -> time
    pub memory_scaling: HashMap<u64, f64>, // file_size -> memory_usage
}

impl FileOperationBenchmarks {
    /// Create a new file operation benchmark suite
    pub fn new() -> Result<Self> {
        let test_data_dir = TempDir::new().context("Failed to create temp directory")?;
        let test_files = Self::generate_test_files(&test_data_dir)?;

        let utilities_under_test = vec![
            "ls".to_string(), "cat".to_string(), "cp".to_string(), "mv".to_string(),
            "rm".to_string(), "grep".to_string(), "find".to_string(), "sort".to_string(),
            "wc".to_string(), "head".to_string(), "tail".to_string(), "cut".to_string(),
            "tee".to_string(), "du".to_string(), "tree".to_string(),
        ];

        Ok(Self {
            test_data_dir,
            test_files,
            utilities_under_test,
        })
    }

    /// Generate test files with various characteristics
    fn generate_test_files(temp_dir: &TempDir) -> Result<HashMap<String, TestFile>> {
        let mut test_files = HashMap::new();

        // Small text file (1KB)
        let small_text = Self::create_test_file(
            temp_dir,
            "small_text.txt",
            1024,
            FileType::SmallText,
            ContentPattern::Lines,
        )?;
        test_files.insert("small_text".to_string(), small_text);

        // Medium text file (1MB)
        let medium_text = Self::create_test_file(
            temp_dir,
            "medium_text.txt",
            1024 * 1024,
            FileType::Text,
            ContentPattern::Words,
        )?;
        test_files.insert("medium_text".to_string(), medium_text);

        // Large text file (10MB)
        let large_text = Self::create_test_file(
            temp_dir,
            "large_text.txt",
            10 * 1024 * 1024,
            FileType::LargeText,
            ContentPattern::Lines,
        )?;
        test_files.insert("large_text".to_string(), large_text);

        // Very large text file (100MB)
        let xl_text = Self::create_test_file(
            temp_dir,
            "xl_text.txt",
            100 * 1024 * 1024,
            FileType::LargeText,
            ContentPattern::Repeated,
        )?;
        test_files.insert("xl_text".to_string(), xl_text);

        // Binary file (5MB)
        let binary_file = Self::create_test_file(
            temp_dir,
            "binary_data.bin",
            5 * 1024 * 1024,
            FileType::Binary,
            ContentPattern::Random,
        )?;
        test_files.insert("binary_data".to_string(), binary_file);

        // Unicode text file (2MB)
        let unicode_file = Self::create_test_file(
            temp_dir,
            "unicode_text.txt",
            2 * 1024 * 1024,
            FileType::Unicode,
            ContentPattern::Unicode,
        )?;
        test_files.insert("unicode_text".to_string(), unicode_file);

        // Mixed content file (3MB)
        let mixed_file = Self::create_test_file(
            temp_dir,
            "mixed_content.dat",
            3 * 1024 * 1024,
            FileType::Mixed,
            ContentPattern::Mixed,
        )?;
        test_files.insert("mixed_content".to_string(), mixed_file);

        // Sparse file (50MB logical, ~1MB physical)
        let sparse_file = Self::create_sparse_file(
            temp_dir,
            "sparse_file.dat",
            50 * 1024 * 1024,
        )?;
        test_files.insert("sparse_file".to_string(), sparse_file);

        Ok(test_files)
    }

    /// Create a test file with specific characteristics
    fn create_test_file(
        temp_dir: &TempDir,
        filename: &str,
        size: u64,
        file_type: FileType,
        pattern: ContentPattern,
    ) -> Result<TestFile> {
        let path = temp_dir.path().join(filename);
        let mut file = File::create(&path).context("Failed to create test file")?;

        match pattern {
            ContentPattern::Random => {
                let mut buffer = vec![0u8; 8192];
                let mut written = 0u64;
                let mut rng = 12345u64; // Simple PRNG for reproducible "random" data

                while written < size {
                    let chunk_size = std::cmp::min(buffer.len() as u64, size - written) as usize;

                    // Generate pseudo-random data
                    for i in 0..chunk_size {
                        rng = rng.wrapping_mul(1103515245).wrapping_add(12345);
                        buffer[i] = (rng >> 16) as u8;
                    }

                    file.write_all(&buffer[..chunk_size])?;
                    written += chunk_size as u64;
                }
            },
            ContentPattern::Repeated => {
                let pattern = b"This is a repeated pattern for testing file operations. ";
                let mut written = 0u64;

                while written < size {
                    let remaining = size - written;
                    let chunk_size = std::cmp::min(pattern.len() as u64, remaining) as usize;
                    file.write_all(&pattern[..chunk_size])?;
                    written += chunk_size as u64;
                }
            },
            ContentPattern::Lines => {
                let mut line_num = 1;
                let mut written = 0u64;

                while written < size {
                    let line = format!("Line number {}: The quick brown fox jumps over the lazy dog.\n", line_num);
                    let line_bytes = line.as_bytes();

                    if written + line_bytes.len() as u64 > size {
                        let remaining = (size - written) as usize;
                        file.write_all(&line_bytes[..remaining])?;
                        break;
                    }

                    file.write_all(line_bytes)?;
                    written += line_bytes.len() as u64;
                    line_num += 1;
                }
            },
            ContentPattern::Words => {
                let words = [
                    "the", "quick", "brown", "fox", "jumps", "over", "lazy", "dog",
                    "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
                    "of", "with", "by", "from", "as", "is", "was", "will", "be",
                    "have", "has", "had", "do", "does", "did", "can", "could",
                    "should", "would", "may", "might", "must", "shall", "will"
                ];

                let mut word_index = 0;
                let mut written = 0u64;

                while written < size {
                    let word = words[word_index % words.len()];
                    let content = if (word_index + 1) % 10 == 0 {
                        format!("{}\n", word)
                    } else {
                        format!("{} ", word)
                    };

                    let content_bytes = content.as_bytes();

                    if written + content_bytes.len() as u64 > size {
                        let remaining = (size - written) as usize;
                        file.write_all(&content_bytes[..remaining])?;
                        break;
                    }

                    file.write_all(content_bytes)?;
                    written += content_bytes.len() as u64;
                    word_index += 1;
                }
            },
            ContentPattern::Unicode => {
                let unicode_chars = "Hello, ‰∏ñÁïå! –ü—Ä–∏–≤–µ—Ç –º–∏—Ä! Bonjour le monde! „Åì„Çì„Å´„Å°„ÅØ‰∏ñÁïå! üåçüöÄ‚ú®üíªüìäüî•";
                let mut written = 0u64;

                while written < size {
                    let line = format!("{} Line {}\n", unicode_chars, written / 100);
                    let line_bytes = line.as_bytes();

                    if written + line_bytes.len() as u64 > size {
                        let remaining = (size - written) as usize;
                        file.write_all(&line_bytes[..remaining])?;
                        break;
                    }

                    file.write_all(line_bytes)?;
                    written += line_bytes.len() as u64;
                }
            },
            ContentPattern::Binary => {
                let mut buffer = vec![0u8; 4096];
                let mut written = 0u64;

                for i in 0..buffer.len() {
                    buffer[i] = (i % 256) as u8;
                }

                while written < size {
                    let chunk_size = std::cmp::min(buffer.len() as u64, size - written) as usize;
                    file.write_all(&buffer[..chunk_size])?;
                    written += chunk_size as u64;
                }
            },
            ContentPattern::Mixed => {
                let patterns = [
                    ContentPattern::Lines,
                    ContentPattern::Binary,
                    ContentPattern::Unicode,
                    ContentPattern::Words,
                ];

                let chunk_size = size / patterns.len() as u64;
                let mut written = 0u64;

                for pattern in &patterns {
                    let target_written = written + chunk_size;
                    let target_written = std::cmp::min(target_written, size);

                    // This is a simplified version - in practice, you'd implement
                    // a more sophisticated mixed pattern generator
                    while written < target_written {
                        let remaining = target_written - written;
                        let chunk = std::cmp::min(1024, remaining);

                        let mut temp_buffer = vec![0u8; chunk as usize];
                        for i in 0..temp_buffer.len() {
                            temp_buffer[i] = ((written + i as u64) % 256) as u8;
                        }

                        file.write_all(&temp_buffer)?;
                        written += chunk;
                    }
                }
            },
            ContentPattern::Sequential => {
                let mut written = 0u64;
                let mut counter = 0u64;

                while written < size {
                    let data = format!("{:016x}\n", counter);
                    let data_bytes = data.as_bytes();

                    if written + data_bytes.len() as u64 > size {
                        let remaining = (size - written) as usize;
                        file.write_all(&data_bytes[..remaining])?;
                        break;
                    }

                    file.write_all(data_bytes)?;
                    written += data_bytes.len() as u64;
                    counter += 1;
                }
            },
        }

        file.flush()?;

        Ok(TestFile {
            name: filename.to_string(),
            size_bytes: size,
            file_type,
            content_pattern: pattern,
            path,
        })
    }

    /// Create a sparse file for testing
    fn create_sparse_file(temp_dir: &TempDir, filename: &str, logical_size: u64) -> Result<TestFile> {
        let path = temp_dir.path().join(filename);
        let mut file = File::create(&path)?;

        // Write some data at the beginning
        file.write_all(b"START OF SPARSE FILE\n")?;

        // Seek to near the end and write some data to create a sparse file
        file.seek(SeekFrom::Start(logical_size - 100))?;
        file.write_all(b"END OF SPARSE FILE\n")?;

        file.flush()?;

        Ok(TestFile {
            name: filename.to_string(),
            size_bytes: logical_size,
            file_type: FileType::Sparse,
            content_pattern: ContentPattern::Binary,
            path,
        })
    }

    /// Run comprehensive file operation benchmarks
    pub fn run_comprehensive_benchmarks(&mut self) -> Result<FileOperationResults> {
        println!("üöÄ Running comprehensive file operation benchmarks...");

        // Run I/O benchmarks
        let io_benchmarks = self.run_io_benchmarks()?;

        // Run utility comparisons
        let mut utility_comparisons = HashMap::new();
        for utility in &self.utilities_under_test.clone() {
            println!("  Benchmarking utility: {}", utility);
            match self.benchmark_utility(utility) {
                Ok(results) => {
                    utility_comparisons.insert(utility.clone(), results);
                },
                Err(e) => {
                    println!("    ‚ö†Ô∏è  Failed to benchmark {}: {}", utility, e);
                }
            }
        }

        // Run memory profiling
        let memory_profiles = self.run_memory_profiling(&utility_comparisons)?;

        // Run scalability tests
        let scalability_results = self.run_scalability_tests()?;

        // Calculate performance summary
        let performance_summary = self.calculate_performance_summary(&utility_comparisons);

        // Get system information
        let mut platform_runner = crate::platforms_enhanced::WindowsBenchmarkRunner::new()?;
        let system_info = platform_runner.get_system_info();

        Ok(FileOperationResults {
            timestamp: chrono::Utc::now(),
            system_info,
            io_benchmarks,
            utility_comparisons,
            performance_summary,
            memory_profiles,
            scalability_results,
        })
    }

    /// Run low-level I/O benchmarks
    fn run_io_benchmarks(&self) -> Result<IOBenchmarkResults> {
        println!("  üìä Running I/O performance benchmarks...");

        let mut read_throughput = HashMap::new();
        let mut write_throughput = HashMap::new();
        let mut seek_times = HashMap::new();
        let mut small_io_latency = HashMap::new();
        let mut large_io_throughput = HashMap::new();
        let mut concurrent_io_performance = HashMap::new();

        // Test read throughput for different file sizes
        for (name, test_file) in &self.test_files {
            if test_file.size_bytes > 0 {
                let throughput = self.benchmark_read_throughput(&test_file.path)?;
                read_throughput.insert(name.clone(), throughput);

                let write_throughput_val = self.benchmark_write_throughput(test_file.size_bytes)?;
                write_throughput.insert(name.clone(), write_throughput_val);

                if test_file.size_bytes > 1024 * 1024 { // Only test seek on larger files
                    let seek_time = self.benchmark_seek_performance(&test_file.path)?;
                    seek_times.insert(name.clone(), seek_time);
                }
            }
        }

        // Small I/O latency test
        let small_latency = self.benchmark_small_io_latency()?;
        small_io_latency.insert("4k_random".to_string(), small_latency);

        // Large I/O throughput test
        let large_throughput = self.benchmark_large_io_throughput()?;
        large_io_throughput.insert("sequential_64k".to_string(), large_throughput);

        // Concurrent I/O test
        let concurrent_perf = self.benchmark_concurrent_io()?;
        concurrent_io_performance.insert("4_threads".to_string(), concurrent_perf);

        Ok(IOBenchmarkResults {
            read_throughput_mbps: read_throughput,
            write_throughput_mbps: write_throughput,
            seek_time_us: seek_times,
            small_io_latency_ns: small_io_latency,
            large_io_throughput: large_io_throughput,
            concurrent_io_performance,
        })
    }

    /// Benchmark read throughput for a file
    fn benchmark_read_throughput(&self, file_path: &Path) -> Result<f64> {
        let mut file = File::open(file_path)?;
        let mut buffer = vec![0u8; 64 * 1024]; // 64KB buffer
        let file_size = file.metadata()?.len();

        let start = Instant::now();
        let mut total_read = 0u64;

        loop {
            match file.read(&mut buffer) {
                Ok(0) => break, // EOF
                Ok(n) => total_read += n as u64,
                Err(e) => return Err(e.into()),
            }
        }

        let duration = start.elapsed();
        let throughput_mbps = (total_read as f64) / (1024.0 * 1024.0) / duration.as_secs_f64();

        Ok(throughput_mbps)
    }

    /// Benchmark write throughput
    fn benchmark_write_throughput(&self, size: u64) -> Result<f64> {
        let temp_file = NamedTempFile::new()?;
        let mut file = temp_file.as_file();
        let buffer = vec![0u8; 64 * 1024]; // 64KB buffer

        let start = Instant::now();
        let mut written = 0u64;

        while written < size {
            let chunk_size = std::cmp::min(buffer.len() as u64, size - written) as usize;
            file.write_all(&buffer[..chunk_size])?;
            written += chunk_size as u64;
        }

        file.flush()?;
        let duration = start.elapsed();
        let throughput_mbps = (written as f64) / (1024.0 * 1024.0) / duration.as_secs_f64();

        Ok(throughput_mbps)
    }

    /// Benchmark seek performance
    fn benchmark_seek_performance(&self, file_path: &Path) -> Result<f64> {
        let mut file = File::open(file_path)?;
        let file_size = file.metadata()?.len();
        let iterations = 1000;

        let start = Instant::now();

        for i in 0..iterations {
            let position = (i * 12345) % file_size; // Pseudo-random positions
            file.seek(SeekFrom::Start(position))?;
        }

        let duration = start.elapsed();
        let avg_seek_time_us = duration.as_micros() as f64 / iterations as f64;

        Ok(avg_seek_time_us)
    }

    /// Benchmark small I/O latency
    fn benchmark_small_io_latency(&self) -> Result<f64> {
        let temp_file = NamedTempFile::new()?;
        let mut file = OpenOptions::new().read(true).write(true).open(temp_file.path())?;

        // Write some data first
        let data = vec![0u8; 4096]; // 4KB
        file.write_all(&data)?;
        file.flush()?;

        let iterations = 1000;
        let mut buffer = vec![0u8; 4096];

        let start = Instant::now();

        for _ in 0..iterations {
            file.seek(SeekFrom::Start(0))?;
            file.read_exact(&mut buffer)?;
        }

        let duration = start.elapsed();
        let avg_latency_ns = duration.as_nanos() as f64 / iterations as f64;

        Ok(avg_latency_ns)
    }

    /// Benchmark large I/O throughput
    fn benchmark_large_io_throughput(&self) -> Result<f64> {
        let temp_file = NamedTempFile::new()?;
        let mut file = temp_file.as_file();
        let buffer = vec![0u8; 1024 * 1024]; // 1MB buffer
        let total_size = 50 * 1024 * 1024; // 50MB total

        let start = Instant::now();
        let mut written = 0u64;

        while written < total_size {
            file.write_all(&buffer)?;
            written += buffer.len() as u64;
        }

        file.flush()?;
        let duration = start.elapsed();
        let throughput_mbps = (written as f64) / (1024.0 * 1024.0) / duration.as_secs_f64();

        Ok(throughput_mbps)
    }

    /// Benchmark concurrent I/O performance
    fn benchmark_concurrent_io(&self) -> Result<f64> {
        use std::sync::Arc;
        use std::thread;

        let thread_count = 4;
        let operations_per_thread = 100;
        let data_size = 64 * 1024; // 64KB per operation

        let start = Instant::now();

        let handles: Vec<_> = (0..thread_count)
            .map(|_| {
                let data_size = data_size;
                let operations = operations_per_thread;

                thread::spawn(move || -> Result<()> {
                    for _ in 0..operations {
                        let temp_file = NamedTempFile::new()?;
                        let mut file = temp_file.as_file();
                        let buffer = vec![0u8; data_size];

                        file.write_all(&buffer)?;
                        file.flush()?;
                    }
                    Ok(())
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap()?;
        }

        let duration = start.elapsed();
        let total_data = (thread_count * operations_per_thread * data_size) as f64;
        let throughput_mbps = total_data / (1024.0 * 1024.0) / duration.as_secs_f64();

        Ok(throughput_mbps)
    }

    /// Benchmark a specific utility
    fn benchmark_utility(&self, utility: &str) -> Result<UtilityComparisonResults> {
        let mut test_results = HashMap::new();
        let mut total_winutils_time = 0.0;
        let mut total_native_time = 0.0;
        let mut total_memory_usage = 0.0;
        let mut total_cpu_usage = 0.0;
        let mut total_io_ops = 0u64;
        let mut accuracy_scores = Vec::new();

        // Test the utility with different file sizes and scenarios
        for (file_name, test_file) in &self.test_files {
            let test_name = format!("{}_{}", utility, file_name);

            match self.run_single_utility_test(utility, test_file) {
                Ok(result) => {
                    total_winutils_time += result.execution_time_ms;
                    total_memory_usage += result.peak_memory_mb;
                    total_cpu_usage += result.cpu_time_ms;
                    accuracy_scores.push(if result.success { 1.0 } else { 0.0 });

                    test_results.insert(test_name, result);
                },
                Err(e) => {
                    println!("    ‚ö†Ô∏è  Test failed for {} with {}: {}", utility, file_name, e);

                    test_results.insert(test_name, SingleTestResult {
                        test_name: format!("{}_{}", utility, file_name),
                        file_size_mb: test_file.size_bytes as f64 / (1024.0 * 1024.0),
                        execution_time_ms: 0.0,
                        throughput_mbps: 0.0,
                        peak_memory_mb: 0.0,
                        cpu_time_ms: 0.0,
                        io_read_mb: 0.0,
                        io_write_mb: 0.0,
                        success: false,
                        error_message: Some(e.to_string()),
                    });
                    accuracy_scores.push(0.0);
                }
            }
        }

        // Try to get native utility performance for comparison
        let native_time = self.benchmark_native_utility(utility).unwrap_or(0.0);
        total_native_time = native_time;

        let speedup_ratio = if total_native_time > 0.0 {
            total_native_time / total_winutils_time
        } else {
            1.0
        };

        let accuracy_score = accuracy_scores.iter().sum::<f64>() / accuracy_scores.len() as f64;

        Ok(UtilityComparisonResults {
            utility_name: utility.to_string(),
            winutils_time_ms: total_winutils_time,
            native_time_ms: total_native_time,
            speedup_ratio,
            memory_usage_mb: total_memory_usage / test_results.len() as f64,
            cpu_usage_percent: total_cpu_usage / total_winutils_time * 100.0,
            io_operations: total_io_ops,
            accuracy_score,
            test_results,
        })
    }

    /// Run a single utility test
    fn run_single_utility_test(&self, utility: &str, test_file: &TestFile) -> Result<SingleTestResult> {
        let winutils_cmd = format!("wu-{}.exe", utility);

        // Determine appropriate arguments based on utility
        let args = self.get_utility_args(utility, test_file);

        let start = Instant::now();
        let start_memory = self.get_current_memory_usage();

        // Execute the command
        let output = Command::new(&winutils_cmd)
            .args(&args)
            .output()
            .context(format!("Failed to execute {}", winutils_cmd))?;

        let execution_time = start.elapsed();
        let end_memory = self.get_current_memory_usage();

        let success = output.status.success();
        let file_size_mb = test_file.size_bytes as f64 / (1024.0 * 1024.0);
        let execution_time_ms = execution_time.as_secs_f64() * 1000.0;

        let throughput_mbps = if execution_time_ms > 0.0 {
            file_size_mb / (execution_time_ms / 1000.0)
        } else {
            0.0
        };

        let peak_memory_mb = (end_memory.saturating_sub(start_memory)) as f64 / (1024.0 * 1024.0);
        let cpu_time_ms = execution_time_ms; // Simplified - in practice, measure actual CPU time

        // Estimate I/O based on utility type and file size
        let (io_read_mb, io_write_mb) = self.estimate_io_usage(utility, test_file);

        Ok(SingleTestResult {
            test_name: format!("{}_{}", utility, test_file.name),
            file_size_mb,
            execution_time_ms,
            throughput_mbps,
            peak_memory_mb,
            cpu_time_ms,
            io_read_mb,
            io_write_mb,
            success,
            error_message: if success { None } else {
                Some(String::from_utf8_lossy(&output.stderr).to_string())
            },
        })
    }

    /// Get appropriate arguments for a utility test
    fn get_utility_args(&self, utility: &str, test_file: &TestFile) -> Vec<String> {
        match utility {
            "ls" => vec![test_file.path.parent().unwrap().to_string_lossy().to_string()],
            "cat" => vec![test_file.path.to_string_lossy().to_string()],
            "wc" => vec![test_file.path.to_string_lossy().to_string()],
            "head" => vec!["-n".to_string(), "100".to_string(), test_file.path.to_string_lossy().to_string()],
            "tail" => vec!["-n".to_string(), "100".to_string(), test_file.path.to_string_lossy().to_string()],
            "sort" => vec![test_file.path.to_string_lossy().to_string()],
            "grep" => vec!["test".to_string(), test_file.path.to_string_lossy().to_string()],
            "find" => vec![
                test_file.path.parent().unwrap().to_string_lossy().to_string(),
                "-name".to_string(),
                test_file.path.file_name().unwrap().to_string_lossy().to_string()
            ],
            "du" => vec![test_file.path.to_string_lossy().to_string()],
            "cut" => vec!["-c".to_string(), "1-10".to_string(), test_file.path.to_string_lossy().to_string()],
            _ => vec![test_file.path.to_string_lossy().to_string()],
        }
    }

    /// Estimate I/O usage for a utility
    fn estimate_io_usage(&self, utility: &str, test_file: &TestFile) -> (f64, f64) {
        let file_size_mb = test_file.size_bytes as f64 / (1024.0 * 1024.0);

        match utility {
            "cat" | "wc" | "head" | "tail" | "sort" | "grep" => (file_size_mb, 0.0), // Read-only
            "cp" => (file_size_mb, file_size_mb), // Read and write
            "mv" => (0.0, 0.0), // Metadata only for same filesystem
            "rm" => (0.0, 0.0), // Metadata only
            "ls" | "find" | "du" => (0.1, 0.0), // Minimal metadata reading
            _ => (file_size_mb * 0.5, 0.0), // Conservative estimate
        }
    }

    /// Get current memory usage (simplified)
    fn get_current_memory_usage(&self) -> u64 {
        use sysinfo::{System, SystemExt, ProcessExt, PidExt};

        let mut system = System::new();
        system.refresh_processes();

        if let Some(process) = system.process(sysinfo::get_current_pid().unwrap()) {
            process.memory() * 1024 // Convert KB to bytes
        } else {
            0
        }
    }

    /// Benchmark native utility (simplified)
    fn benchmark_native_utility(&self, utility: &str) -> Result<f64> {
        // This is a simplified implementation
        // In practice, you'd run the actual native command and measure its performance

        let native_cmd = match utility {
            "ls" => "dir",
            "cat" => "type",
            "cp" => "copy",
            "mv" => "move",
            "rm" => "del",
            "grep" => "findstr",
            _ => return Ok(0.0), // No native equivalent
        };

        if let Some(test_file) = self.test_files.values().next() {
            let start = Instant::now();

            let _output = Command::new(native_cmd)
                .arg(test_file.path.to_string_lossy().as_ref())
                .output();

            let duration = start.elapsed();
            Ok(duration.as_secs_f64() * 1000.0)
        } else {
            Ok(0.0)
        }
    }

    /// Run memory profiling for utilities
    fn run_memory_profiling(&self, utility_results: &HashMap<String, UtilityComparisonResults>) -> Result<HashMap<String, MemoryProfile>> {
        println!("  üß† Running memory profiling...");

        let mut profiles = HashMap::new();

        for (utility, _results) in utility_results {
            // This is a simplified memory profiling implementation
            // In practice, you'd use tools like jemalloc profiling or Windows Performance API

            let profile = MemoryProfile {
                utility_name: utility.clone(),
                peak_usage_mb: 10.0 + (utility.len() as f64 * 0.5), // Simulated
                average_usage_mb: 5.0 + (utility.len() as f64 * 0.3), // Simulated
                allocation_count: 1000,
                deallocation_count: 950,
                memory_leaks_mb: 0.1,
                gc_collections: 0, // Not applicable for Rust
                memory_timeline: vec![
                    MemorySnapshot {
                        timestamp_ms: 0,
                        memory_usage_mb: 2.0,
                        heap_size_mb: 1.5,
                        stack_size_mb: 0.5,
                    },
                    MemorySnapshot {
                        timestamp_ms: 100,
                        memory_usage_mb: 8.0,
                        heap_size_mb: 7.0,
                        stack_size_mb: 1.0,
                    },
                    MemorySnapshot {
                        timestamp_ms: 200,
                        memory_usage_mb: 5.0,
                        heap_size_mb: 4.0,
                        stack_size_mb: 1.0,
                    },
                ],
            };

            profiles.insert(utility.clone(), profile);
        }

        Ok(profiles)
    }

    /// Run scalability tests
    fn run_scalability_tests(&self) -> Result<ScalabilityResults> {
        println!("  üìà Running scalability tests...");

        // File size scaling test
        let file_sizes = vec![1024, 10_240, 102_400, 1_024_000, 10_240_000]; // 1KB to 10MB
        let mut file_size_scaling = HashMap::new();

        for size in file_sizes {
            let throughput = self.benchmark_write_throughput(size)?;
            file_size_scaling.insert(size, throughput);
        }

        // Concurrent operations test
        let thread_counts = vec![1, 2, 4, 8, 16];
        let mut concurrent_operations = HashMap::new();

        for thread_count in thread_counts {
            let throughput = self.benchmark_concurrent_operations(thread_count)?;
            concurrent_operations.insert(thread_count, throughput);
        }

        // Directory size scaling (simplified)
        let file_counts = vec![10, 100, 1000, 5000];
        let mut directory_size_scaling = HashMap::new();

        for file_count in file_counts {
            let time = self.benchmark_directory_operations(file_count)?;
            directory_size_scaling.insert(file_count, time);
        }

        // Memory scaling
        let memory_test_sizes = vec![1_024_000, 10_240_000, 102_400_000]; // 1MB to 100MB
        let mut memory_scaling = HashMap::new();

        for size in memory_test_sizes {
            let memory_usage = size as f64 * 1.2; // Estimate 20% overhead
            memory_scaling.insert(size, memory_usage);
        }

        Ok(ScalabilityResults {
            file_size_scaling,
            concurrent_operations,
            directory_size_scaling,
            memory_scaling,
        })
    }

    /// Benchmark concurrent operations
    fn benchmark_concurrent_operations(&self, thread_count: usize) -> Result<f64> {
        use std::thread;
        use std::sync::Arc;

        let operations_per_thread = 50;
        let data_size = 64 * 1024; // 64KB per operation

        let start = Instant::now();

        let handles: Vec<_> = (0..thread_count)
            .map(|_| {
                thread::spawn(move || -> Result<()> {
                    for _ in 0..operations_per_thread {
                        let temp_file = NamedTempFile::new()?;
                        let mut file = temp_file.as_file();
                        let buffer = vec![0u8; data_size];

                        file.write_all(&buffer)?;
                        file.flush()?;

                        // Read it back
                        file.seek(SeekFrom::Start(0))?;
                        let mut read_buffer = vec![0u8; data_size];
                        file.read_exact(&mut read_buffer)?;
                    }
                    Ok(())
                })
            })
            .collect();

        for handle in handles {
            handle.join().unwrap()?;
        }

        let duration = start.elapsed();
        let total_operations = thread_count * operations_per_thread;
        let ops_per_second = total_operations as f64 / duration.as_secs_f64();

        Ok(ops_per_second)
    }

    /// Benchmark directory operations
    fn benchmark_directory_operations(&self, file_count: usize) -> Result<f64> {
        let temp_dir = TempDir::new()?;

        let start = Instant::now();

        // Create files
        for i in 0..file_count {
            let file_path = temp_dir.path().join(format!("test_file_{}.txt", i));
            let mut file = File::create(&file_path)?;
            file.write_all(b"test content")?;
        }

        // List directory (simulate ls operation)
        let _entries: Vec<_> = std::fs::read_dir(temp_dir.path())?.collect();

        let duration = start.elapsed();
        Ok(duration.as_secs_f64() * 1000.0) // Return time in milliseconds
    }

    /// Calculate performance summary
    fn calculate_performance_summary(&self, utility_results: &HashMap<String, UtilityComparisonResults>) -> FileOperationSummary {
        if utility_results.is_empty() {
            return FileOperationSummary {
                total_tests: 0,
                successful_tests: 0,
                failed_tests: 0,
                average_speedup: 0.0,
                best_speedup: 0.0,
                worst_speedup: 0.0,
                total_data_processed_gb: 0.0,
                average_throughput_mbps: 0.0,
                memory_efficiency_ratio: 0.0,
                cpu_efficiency_ratio: 0.0,
            };
        }

        let speedups: Vec<f64> = utility_results.values().map(|r| r.speedup_ratio).collect();
        let total_tests = utility_results.len();
        let successful_tests = utility_results.values()
            .filter(|r| r.accuracy_score > 0.9)
            .count();

        let average_speedup = speedups.iter().sum::<f64>() / speedups.len() as f64;
        let best_speedup = speedups.iter().fold(0.0f64, |acc, &x| acc.max(x));
        let worst_speedup = speedups.iter().fold(f64::INFINITY, |acc, &x| acc.min(x));

        let total_data_gb = self.test_files.values()
            .map(|f| f.size_bytes as f64)
            .sum::<f64>() / (1024.0 * 1024.0 * 1024.0);

        let average_throughput = utility_results.values()
            .flat_map(|r| r.test_results.values())
            .filter(|t| t.success)
            .map(|t| t.throughput_mbps)
            .sum::<f64>() / utility_results.values()
            .flat_map(|r| r.test_results.values())
            .filter(|t| t.success)
            .count() as f64;

        FileOperationSummary {
            total_tests,
            successful_tests,
            failed_tests: total_tests - successful_tests,
            average_speedup,
            best_speedup,
            worst_speedup,
            total_data_processed_gb: total_data_gb,
            average_throughput_mbps: average_throughput,
            memory_efficiency_ratio: 0.85, // Simplified calculation
            cpu_efficiency_ratio: 0.90,    // Simplified calculation
        }
    }

    /// Generate performance report
    pub fn generate_performance_report(&self, results: &FileOperationResults) -> String {
        let mut report = String::new();

        report.push_str("# File Operation Performance Report\n\n");
        report.push_str(&format!("**Generated:** {}\n\n", results.timestamp.format("%Y-%m-%d %H:%M:%S UTC")));

        // System Information
        report.push_str("## System Information\n\n");
        report.push_str(&format!("- **OS:** {} {}\n", results.system_info.platform, results.system_info.os_version));
        report.push_str(&format!("- **CPU:** {} ({} cores)\n", results.system_info.cpu_brand, results.system_info.cpu_count));
        report.push_str(&format!("- **Memory:** {:.1} GB total, {:.1} GB available\n",
            results.system_info.total_memory as f64 / 1024.0 / 1024.0 / 1024.0,
            results.system_info.available_memory as f64 / 1024.0 / 1024.0 / 1024.0));

        // Performance Summary
        report.push_str("\n## Performance Summary\n\n");
        let summary = &results.performance_summary;
        report.push_str(&format!("- **Total Tests:** {}\n", summary.total_tests));
        report.push_str(&format!("- **Successful Tests:** {} ({:.1}%)\n",
            summary.successful_tests,
            summary.successful_tests as f64 / summary.total_tests as f64 * 100.0));
        report.push_str(&format!("- **Average Speedup:** {:.2}x\n", summary.average_speedup));
        report.push_str(&format!("- **Best Speedup:** {:.2}x\n", summary.best_speedup));
        report.push_str(&format!("- **Data Processed:** {:.2} GB\n", summary.total_data_processed_gb));
        report.push_str(&format!("- **Average Throughput:** {:.1} MB/s\n", summary.average_throughput_mbps));

        // I/O Benchmark Results
        report.push_str("\n## I/O Performance\n\n");
        report.push_str("### Read Throughput (MB/s)\n\n");
        for (name, throughput) in &results.io_benchmarks.read_throughput_mbps {
            report.push_str(&format!("- **{}:** {:.1} MB/s\n", name, throughput));
        }

        report.push_str("\n### Write Throughput (MB/s)\n\n");
        for (name, throughput) in &results.io_benchmarks.write_throughput_mbps {
            report.push_str(&format!("- **{}:** {:.1} MB/s\n", name, throughput));
        }

        // Utility Comparison Results
        report.push_str("\n## Utility Performance Comparison\n\n");
        report.push_str("| Utility | WinUtils (ms) | Native (ms) | Speedup | Memory (MB) | Accuracy |\n");
        report.push_str("|---------|---------------|-------------|---------|-------------|----------|\n");

        for (utility, results) in &results.utility_comparisons {
            report.push_str(&format!(
                "| {} | {:.1} | {:.1} | {:.2}x | {:.1} | {:.1}% |\n",
                utility,
                results.winutils_time_ms,
                results.native_time_ms,
                results.speedup_ratio,
                results.memory_usage_mb,
                results.accuracy_score * 100.0
            ));
        }

        report
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_file_operation_benchmarks_creation() {
        let benchmarks = FileOperationBenchmarks::new();
        assert!(benchmarks.is_ok());

        let benchmarks = benchmarks.unwrap();
        assert!(!benchmarks.test_files.is_empty());
        assert!(!benchmarks.utilities_under_test.is_empty());
    }

    #[test]
    fn test_test_file_generation() {
        let temp_dir = TempDir::new().unwrap();
        let test_files = FileOperationBenchmarks::generate_test_files(&temp_dir).unwrap();

        assert!(!test_files.is_empty());

        // Verify files were actually created
        for (name, test_file) in &test_files {
            assert!(test_file.path.exists(), "Test file {} should exist", name);

            if !matches!(test_file.file_type, FileType::Sparse) {
                let metadata = std::fs::metadata(&test_file.path).unwrap();
                assert!(metadata.len() > 0, "Test file {} should have content", name);
            }
        }
    }

    #[test]
    fn test_io_benchmarking() {
        let benchmarks = FileOperationBenchmarks::new().unwrap();

        // Test read throughput on a small file
        if let Some(test_file) = benchmarks.test_files.values().next() {
            let result = benchmarks.benchmark_read_throughput(&test_file.path);
            assert!(result.is_ok());

            let throughput = result.unwrap();
            assert!(throughput > 0.0, "Read throughput should be positive");
        }
    }

    #[test]
    fn test_write_throughput() {
        let benchmarks = FileOperationBenchmarks::new().unwrap();

        let result = benchmarks.benchmark_write_throughput(1024 * 1024); // 1MB
        assert!(result.is_ok());

        let throughput = result.unwrap();
        assert!(throughput > 0.0, "Write throughput should be positive");
    }

    #[test]
    fn test_utility_args_generation() {
        let benchmarks = FileOperationBenchmarks::new().unwrap();

        if let Some(test_file) = benchmarks.test_files.values().next() {
            let args = benchmarks.get_utility_args("cat", test_file);
            assert!(!args.is_empty());
            assert!(args[0].contains(&test_file.name));

            let args = benchmarks.get_utility_args("ls", test_file);
            assert!(!args.is_empty());

            let args = benchmarks.get_utility_args("grep", test_file);
            assert!(args.len() >= 2);
            assert_eq!(args[0], "test");
        }
    }
}
