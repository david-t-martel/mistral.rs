{
  "model": "mistralrs-test",
  "temperature": 0.7,
  "max_tokens": 100,
  "top_p": 0.9,
  "frequency_penalty": 0.0,
  "presence_penalty": 0.0,
  "stop": ["\n\n"],
  "stream": false
}
